{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image captioning project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description - Flickr8k dataset 8000 images , 5 caption for each image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "from time import time\n",
    "import pickle\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
    "from keras.layers.merge import add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read text captions\n",
    "def readTextfile(path):\n",
    "    with open(path) as f:\n",
    "        \n",
    "        captions = f.read() #readlines will also split caption that takes two lines of the files\n",
    "    return captions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions  = readTextfile(\"flickr8k/Flickr_Data/Flickr_Data/Flickr_TextData/Flickr8k.token.txt\")\n",
    "captions = captions.split('\\n')[:-1]\n",
    "#split each of the lines about \\n and from each row take the last element very basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1000268201_693b08cb0e.jpg#0\\tA child in a pink dress is climbing up a set of stairs in an entry way .'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions[0]\n",
    "#the number after #i.e 0 in this case represents caption no. so it is 0 for 1st caption, 1 for 2nd and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000268201_693b08cb0e.jpg#0\n",
      "A child in a pink dress is climbing up a set of stairs in an entry way .\n"
     ]
    }
   ],
   "source": [
    "first,second = captions[0].split('\\t') # first part is for image, second part is the caption of that image\n",
    "print(first)\n",
    "print(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to Map each Image with the list of captions it has\n",
    "descriptions = {}\n",
    "\n",
    "for x in captions:\n",
    "    first,second = x.split('\\t')\n",
    "    img_name = first.split(\".\")[0]\n",
    "    \n",
    "    #if the image id is already present or not\n",
    "    if descriptions.get(img_name) is None:\n",
    "        descriptions[img_name] = []\n",
    "    \n",
    "    descriptions[img_name].append(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = \"flickr8k/Flickr_Data/Flickr_Data/Images/\"\n",
    "import cv2\n",
    "img = cv2.imread(IMG_PATH+\"1000268201_693b08cb0e.jpg\")\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't remove stopwords else our model will not know when to use common words like thhe, and etc.\n",
    "# also don't feed stemmed words as the model will learn these words later\n",
    "#we will convert our text to lowe case\n",
    "# we will remove numbers, and punctuation marks\n",
    "\n",
    "def cleantext(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(\"[^a-z]+\",\" \",sentence) #using regex to get rid of all non-alphabets and replacing them with space\n",
    "    sentence = sentence.split()\n",
    "    \n",
    "    sentence  = [s for s in sentence if len(s)>1]\n",
    "    sentence = \" \".join(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat is sitting over the house'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleantext(\"A cat is sitting over the house # 64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning all Captions\n",
    "for key,caption_list in descriptions.items():\n",
    "    for i in range(len(caption_list)):\n",
    "        caption_list[i] = cleantext(caption_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['child in pink dress is climbing up set of stairs in an entry way',\n",
       " 'girl going into wooden building',\n",
       " 'little girl climbing into wooden playhouse',\n",
       " 'little girl climbing the stairs to her playhouse',\n",
       " 'little girl in pink dress going into wooden cabin']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions[\"1000268201_693b08cb0e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data to text file so use it for later purpose\n",
    "\n",
    "with open(\"descriptions1.txt\",\"w\") as f:\n",
    "    f.write(str(descriptions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will open our code from this point only\n",
    "with open(\"descriptions1.txt\",'r') as f:\n",
    "    descriptions= f.read()\n",
    "    \n",
    "json_acceptable_string = descriptions.replace(\"'\",\"\\\"\")\n",
    "descriptions = json.loads(json_acceptable_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size : 8424\n"
     ]
    }
   ],
   "source": [
    "#creating a set to store all the vocabulary from all the captions \n",
    "vocab = set()\n",
    "for key in descriptions.keys():\n",
    "    [vocab.update(sentence.split()) for sentence in descriptions[key]]\n",
    "     # basically  we iterate over all the images( keys) and then take their captions\n",
    "        # then we split each caption about space (' ') and store each word in the vocab set\n",
    "        # vocab will only have unique words\n",
    "    \n",
    "    \n",
    "print(\"Vocab Size : %d\"% len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words 373837\n"
     ]
    }
   ],
   "source": [
    "# Total No of words across all the sentences\n",
    "totalwords = []\n",
    "\n",
    "for key in descriptions.keys():\n",
    "    [totalwords.append(i) for des in descriptions[key] for i in des.split()] \n",
    "    #using list comprehension to append each word in totalwords\n",
    "   \n",
    "print(\"Total Words %d\"%len(totalwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.Counter'>\n"
     ]
    }
   ],
   "source": [
    "# Filter Words from the Vocab according to certain threshold frequncy \n",
    "# because we want to still shorten this vocab size and for that reason we take the words above a certain threshold frequency\n",
    "\n",
    "# returns a dict subclass \n",
    "counter = collections.Counter(totalwords)\n",
    "print(type(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8424\n"
     ]
    }
   ],
   "source": [
    "freqcount = dict(counter)\n",
    "print(len(freqcount.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#sorting the dictionary in order of frequency count\n",
    "sorted_freqcount = sorted(freqcount.items(),reverse = True,key = lambda x:x[1])\n",
    "\n",
    "threshold = 10\n",
    "print(type(sorted_freqcount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_freqcount = [x for x in sorted_freqcount if x[1]>threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1845\n"
     ]
    }
   ],
   "source": [
    "new_totalwords = [x[0] for x in sorted_freqcount] \n",
    "print(len(new_totalwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'the', 'on', 'is', 'and', 'dog', 'with', 'man', 'of', 'two', 'white', 'black', 'boy', 'are', 'woman', 'girl', 'to', 'wearing', 'at', 'people', 'water', 'red', 'young', 'brown', 'an', 'his', 'blue', 'dogs', 'running', 'through', 'playing', 'while', 'shirt', 'down', 'standing', 'ball', 'little', 'grass', 'snow', 'child', 'person', 'jumping', 'over', 'three', 'front', 'sitting', 'holding', 'up', 'field', 'small', 'by', 'large', 'green', 'one', 'group', 'yellow', 'her', 'walking', 'children', 'men', 'into', 'air', 'beach', 'near', 'mouth', 'jumps', 'another', 'for', 'street', 'runs', 'its', 'from', 'riding', 'stands', 'as', 'bike', 'girls', 'outside', 'other', 'off', 'out', 'rock', 'next', 'play', 'orange', 'looking', 'pink', 'player', 'camera', 'their', 'pool', 'hat', 'jacket', 'boys', 'women', 'around', 'behind', 'some', 'background', 'dirt', 'toy', 'soccer', 'sits', 'dressed', 'has', 'wall', 'mountain', 'walks', 'crowd', 'along', 'plays', 'stand', 'looks', 'building', 'park', 'climbing', 'four', 'top', 'face', 'football', 'across', 'grassy', 'holds', 'sand', 'stick', 'smiling', 'ocean', 'rides', 'swimming', 'hill', 'skateboard', 'carrying', 'doing', 'each', 'tennis', 'car', 'tree', 'snowy', 'baby', 'picture', 'bicycle', 'hair', 'together', 'jump', 'him', 'it', 'road', 'area', 'that', 'basketball', 'tan', 'back', 'trick', 'race', 'swing', 'head', 'shorts', 'bench', 'sidewalk', 'covered', 'run', 'catch', 'game', 'sit', 'helmet', 'ground', 'hand', 'dress', 'something', 'fence', 'kids', 'being', 'frisbee', 'lake', 'path', 'city', 'ramp', 'walk', 'wave', 'skateboarder', 'several', 'long', 'purple', 'side', 'there', 'slide', 'baseball', 'high', 'posing', 'track', 'players', 'wooden', 'big', 'sunglasses', 'watches', 'boat', 'uniform', 'dark', 'coat', 'trees', 'look', 'them', 'pants', 'table', 'rocks', 'ride', 'rope', 'watching', 'motorcycle', 'grey', 'suit', 'couple', 'towards', 'arms', 'beside', 'hands', 'under', 'rocky', 'sign', 'watch', 'snowboarder', 'river', 'horse', 'does', 'above', 'racing', 'older', 'jeans', 'lady', 'ice', 'colored', 'striped', 'colorful', 'pose', 'who', 'onto', 'woods', 'midair', 'guy', 'he', 'glasses', 'taking', 'leaps', 'mountains', 'haired', 'asian', 'climbs', 'playground', 'blonde', 'yard', 'against', 'collar', 'performing', 'cliff', 'hockey', 'cap', 'blond', 'bird', 'smiles', 'body', 'open', 'laying', 'surfer', 'team', 'many', 'rider', 'after', 'chasing', 'kid', 'wet', 'fountain', 'skier', 'surrounded', 'outdoors', 'flying', 'during', 'inside', 'old', 'brick', 'biker', 'others', 'shore', 'edge', 'away', 'takes', 'light', 'toddler', 'guitar', 'hanging', 'trying', 'very', 'middle', 'someone', 'forest', 'five', 'backpack', 'night', 'outfit', 'gray', 'pole', 'bed', 'talking', 'object', 'steps', 'making', 'floor', 'nearby', 'whilst', 'line', 'about', 'going', 'flowers', 'past', 'arm', 'sky', 'toward', 'tall', 'trail', 'surfboard', 'swinging', 'eating', 'dancing', 'board', 'waves', 'this', 'poses', 'bridge', 'leaves', 'all', 'day', 'leaping', 'window', 'outdoor', 'bag', 'course', 'clothes', 'legs', 'fighting', 'chair', 'room', 'costume', 'house', 'leash', 'plastic', 'shallow', 'clothing', 'splashing', 'stone', 'carries', 'shirts', 'ready', 'climber', 'between', 'obstacle', 'getting', 'bright', 'catches', 'sliding', 'adult', 'they', 'swings', 'skateboarding', 'waiting', 'bathing', 'sweater', 'concrete', 'sled', 'trampoline', 'lawn', 'gear', 'winter', 'wears', 'metal', 'mud', 'skiing', 'uniforms', 'male', 'jersey', 'railing', 'number', 'sandy', 'tongue', 'fire', 'stream', 'store', 'train', 'golden', 'pulling', 'set', 'stairs', 'catching', 'distance', 'throwing', 'upside', 'sun', 'lot', 'drink', 'bar', 'get', 'fishing', 'gets', 'tries', 'adults', 'smile', 'shirtless', 'overlooking', 'like', 'swims', 'flies', 'rail', 'ski', 'female', 'couch', 'wooded', 'tricks', 'makes', 'busy', 'drinking', 'puppy', 'chases', 'lying', 'animal', 'tire', 'vest', 'flag', 'surfing', 'swim', 'performs', 'american', 'cellphone', 'pond', 'reading', 'laughing', 'right', 'trunks', 'leaning', 'flip', 'shopping', 'huge', 'food', 'puddle', 'dock', 'she', 'slides', 'horses', 'eyes', 'hats', 'photo', 'bat', 'shoes', 'nose', 'sunset', 'left', 'kayak', 'bubbles', 'cart', 'truck', 'climb', 'coming', 'stunt', 'deep', 'snowboard', 'hold', 'scarf', 'feet', 'life', 'no', 'or', 'bikes', 'family', 'umbrella', 'waterfall', 'goal', 'view', 'elderly', 'equipment', 'restaurant', 'tent', 'skating', 'hurdle', 'greyhound', 'biting', 'both', 'skis', 'lone', 'setting', 'harness', 'take', 'falling', 'wetsuit', 'bus', 'mask', 'muddy', 'hiker', 'flags', 'vehicle', 'dry', 'paper', 'skirt', 'bags', 'guys', 'court', 'surf', 'crowded', 'fight', 'sweatshirt', 'dresses', 'structure', 'ledge', 'book', 'tank', 'bmx', 'six', 'be', 'pile', 'slope', 'go', 'cigarette', 'german', 'raft', 'airborne', 'short', 'driving', 'skate', 'kick', 'have', 'diving', 'faces', 'cross', 'cement', 'inflatable', 'goggles', 'wood', 'subway', 'costumes', 'graffiti', 'goes', 'canoe', 'parking', 'teenage', 'cyclist', 'dance', 'kicking', 'bottle', 'shaking', 'splashes', 'buildings', 'fallen', 'turn', 'parade', 'hit', 'shepherd', 'ears', 'ring', 'sports', 'jackets', 'gathered', 'blanket', 'pictures', 'low', 'backyard', 'throws', 'smaller', 'closeup', 'tunnel', 'band', 'full', 'silver', 'chairs', 'microphone', 'smoking', 'leather', 'held', 'sunny', 'bikini', 'wheel', 'piece', 'boots', 'event', 'balls', 'beard', 'bull', 'surface', 'cars', 'cat', 'fluffy', 'stage', 'kicks', 'painted', 'make', 'pushing', 'using', 'bicyclist', 'hiking', 'outfits', 'box', 'rugby', 'statue', 'stuffed', 'pointing', 'paint', 'sticks', 'steep', 'gold', 'bald', 'bucket', 'blowing', 'glass', 'tube', 'door', 'swimsuit', 'drinks', 'scooter', 'suits', 'sleeping', 'flower', 'throw', 'shot', 'volleyball', 'cow', 'furry', 'hugging', 'corner', 'wrestling', 'net', 'crossing', 'wrestle', 'same', 'hangs', 'hind', 'cowboy', 'points', 'leg', 'motorcyclist', 'staring', 'leans', 'attempting', 'police', 'kissing', 'spectators', 'lays', 'wading', 'sheep', 'party', 'attempts', 'few', 'teams', 'show', 'bunch', 'log', 'facing', 'below', 'beige', 'bicycles', 'close', 'puppies', 'cup', 'snowboarding', 'hoop', 'desert', 'garden', 'african', 'wide', 'fenced', 'way', 'sprinkler', 'fast', 'beautiful', 'sticking', 'underwater', 'attached', 'fish', 'gym', 'softball', 'gather', 'competition', 'eats', 'waving', 'end', 'onlookers', 'naked', 'filled', 'phone', 'wings', 'poles', 'racket', 'racetrack', 'which', 'dances', 'talks', 'rain', 'gravel', 'base', 'rolling', 'prepares', 'seat', 'lit', 'empty', 'clear', 'motocross', 'racer', 'seated', 'hula', 'do', 'headband', 'signs', 'platform', 'toys', 'heads', 'neck', 'wear', 'hits', 'ladies', 'pushes', 'plaid', 'branch', 'mohawk', 'market', 'downhill', 'birds', 'bride', 'round', 'pavement', 'paddling', 'having', 'public', 'handstand', 'just', 'shop', 'traffic', 'rough', 'shoulder', 'scene', 'among', 'skateboards', 'different', 'reads', 'bearded', 'gloves', 'chewing', 'school', 'beer', 'hose', 'thrown', 'landscape', 'rural', 'drives', 'dirty', 'bars', 'barefoot', 'tie', 'urban', 'kitchen', 'teeth', 'races', 'cream', 'balloon', 'resting', 'foot', 'tug', 'splash', 'display', 'carnival', 'before', 'bottom', 'cricket', 'painting', 'lies', 'paved', 'goalie', 'wait', 'indoor', 'mother', 'plants', 'carpet', 'creek', 'says', 'waits', 'younger', 'rapids', 'wedding', 'flight', 'smoke', 'match', 'opposing', 'lined', 'half', 'headphones', 'animals', 'pipe', 'lap', 'fall', 'showing', 'block', 'stadium', 'skates', 'greyhounds', 'blows', 'wrestler', 'moving', 'boats', 'gun', 'parked', 'reaching', 'onstage', 'santa', 'art', 'seen', 'paddle', 'video', 'where', 'mouths', 'foreground', 'war', 'talk', 'chase', 'bandanna', 'third', 'instruments', 'singing', 'lights', 'runner', 'falls', 'can', 'deck', 'atv', 'helmets', 'pulled', 'photograph', 'ear', 'motorbike', 'wire', 'funny', 'matching', 'poodle', 'curly', 'shooting', 'spotted', 'ropes', 'newspaper', 'outstretched', 'floating', 'fly', 'audience', 'brightly', 'hitting', 'fair', 'try', 'unicycle', 'reaches', 'amusement', 'hay', 'staircase', 'christmas', 'shakes', 'duck', 'hole', 'atop', 'spray', 'bushes', 'preparing', 'bank', 'alongside', 'purse', 'retriever', 'pack', 'martial', 'shoulders', 'wheelie', 'raises', 'bubble', 'teenagers', 'giant', 'grinding', 'appears', 'terrain', 'country', 'skiers', 'finger', 'hooded', 'stop', 'follows', 'formation', 'chain', 'roller', 'plate', 'pulls', 'hoops', 'kite', 'digging', 'larger', 'surfs', 'muzzle', 'rowing', 'putting', 'hikers', 'alone', 'station', 'denim', 'enjoys', 'cold', 'hoodie', 'music', 'balancing', 'jeep', 'covering', 'perform', 'muzzled', 'rodeo', 'row', 'kneeling', 'paddles', 'puts', 'pier', 'giving', 'shaggy', 'picnic', 'backwards', 'gives', 'indoors', 'spinning', 'himself', 'shadow', 'parachute', 'jumped', 'hang', 'break', 'shows', 'handrail', 'laughs', 'leap', 'bite', 'backs', 'cut', 'safety', 'pull', 'playfully', 'clouds', 'backpacks', 'writing', 'ladder', 'enjoying', 'owner', 'competing', 'necklace', 'gate', 'counter', 'sniffing', 'licking', 'riders', 'terrier', 'seven', 'bites', 'construction', 'machine', 'fetch', 'bikers', 'skinned', 'underneath', 'jungle', 'made', 'cloth', 'fur', 'mound', 'basket', 'violin', 'doorway', 'fingers', 'passing', 'tackle', 'bowl', 'rink', 'crouches', 'quickly', 'paws', 'sea', 'mid', 'collie', 'step', 'computer', 'camouflage', 'these', 'splashed', 'hillside', 'referee', 'taken', 'coats', 'professional', 'rollerblades', 'decorated', 'friend', 'pigeons', 'ducks', 'military', 'wheelchair', 'spots', 'waters', 'kayaking', 'hot', 'helps', 'bouncing', 'straw', 'float', 'tracks', 'balances', 'lean', 'trunk', 'skater', 'homeless', 'opposite', 'driver', 'caught', 'rollerblading', 'barrier', 'cone', 'stump', 'stroller', 'courtyard', 'heavy', 'balloons', 'streets', 'biking', 'without', 'wagon', 'landing', 'bear', 'coffee', 'shown', 'formal', 'frame', 'peace', 'kiss', 'land', 'mirror', 'dune', 'walkway', 'screen', 'karate', 'arts', 'watched', 'string', 'tents', 'chest', 'home', 'hug', 'laugh', 'clown', 'sooners', 'plane', 'climbers', 'uses', 'motorcycles', 'cardboard', 'helping', 'shaped', 'eat', 'suspended', 'makeup', 'blurry', 'monkey', 'speed', 'coaster', 'direction', 'fetching', 'reach', 'medium', 'sized', 'range', 'rolls', 'tattoo', 'barking', 'drum', 'frozen', 'kneels', 'mountainside', 'happily', 'jogging', 'put', 'bending', 'neon', 'asleep', 'eye', 'begins', 'jean', 'but', 'rubber', 'well', 'flowered', 'headscarf', 'practicing', 'touching', 'crashing', 'cyclists', 'see', 'petting', 'raised', 'dead', 'blow', 'blocks', 'knit', 'miami', 'jerseys', 'mountaintop', 'sprayed', 'attire', 'teenager', 'plain', 'cake', 'turning', 'dusk', 'balcony', 'leaving', 'crosses', 'only', 'forward', 'training', 'tires', 'corn', 'shoreline', 'bend', 'dribbles', 'surrounding', 'pass', 'indian', 'airplane', 'boxing', 'grinds', 'puck', 'overalls', 'working', 'lab', 'rest', 'porch', 'boardwalk', 'lay', 'curve', 'hugs', 'bicyclists', 'town', 'almost', 'lots', 'waterskiing', 'skirts', 'father', 'curb', 'patch', 'hills', 'snowball', 'photographer', 'square', 'fake', 'grocery', 'action', 'racquet', 'comes', 'policeman', 'coach', 'tackled', 'wrestlers', 'valley', 'rests', 'jet', 'pine', 'closed', 'friends', 'golf', 'cloudy', 'themselves', 'sides', 'disc', 'sport', 'kayaker', 'free', 'crouching', 'ahead', 'tail', 'tricycle', 'pit', 'wrapped', 'smokes', 'dives', 'muzzles', 'officer', 'eastern', 'sumo', 'rainbow', 'sculpture', 'mat', 'barrel', 'colors', 'strip', 'warm', 'time', 'type', 'flips', 'first', 'candles', 'towel', 'lift', 'moves', 'ribbon', 'spread', 'tattoos', 'following', 'class', 'vehicles', 'though', 'scuba', 'multicolored', 'image', 'students', 'hike', 'swimmer', 'gathering', 'redheaded', 'cheerleaders', 'part', 'cones', 'members', 'thumbs', 'groom', 'beam', 'patio', 'wheeler', 'woodland', 'cave', 'sharp', 'topless', 'sandals', 'leading', 'spraying', 'soda', 'passes', 'knee', 'bow', 'vests', 'scarves', 'wine', 'palm', 'catcher', 'speaking', 'multi', 'wheeled', 'dust', 'brush', 'silhouette', 'crosswalk', 'kisses', 'turns', 'surfers', 'enjoy', 'fans', 'move', 'leads', 'fancy', 'tiger', 'drums', 'merry', 'kiddie', 'chews', 'obama', 'also', 'turned', 'scaling', 'item', 'foam', 'shower', 'happy', 'itself', 'marching', 'apron', 'church', 'sofa', 'place', 'grab', 'tables', 'cheek', 'help', 'pirate', 'shoot', 'peak', 'touches', 'living', 'seats', 'bare', 'listening', 'crawls', 'embrace', 'sprinklers', 'carry', 'tutu', 'herself', 'sleeps', 'center', 'protest', 'banner', 'aged', 'swan', 'hard', 'various', 'played', 'carriage', 'benches', 'chased', 'rug', 'motion', 'birthday', 'boogie', 'skull', 'pitbull', 'circle', 'cover', 'case', 'innertube', 'agility', 'stares', 'ridden', 'teen', 'rafting', 'farm', 'beads', 'foggy', 'stomach', 'leashes', 'sword', 'inline', 'snowsuit', 'licks', 'protective', 'huddle', 'what', 'pitcher', 'japanese', 'walls', 'tackling', 'rollerblader', 'chinese', 'pajamas', 'workers', 'boxer', 'skinny', 'hallway', 'flops', 'boulder', 'print', 'thin', 'cafe', 'sideways', 'device', 'railroad', 'floats', 'sheet', 'you', 'retrieving', 'feeding', 'raising', 'fun', 'rows', 'not', 'wind', 'pouring', 'sings', 'picking', 'neighborhood', 'single', 'spiderman', 'work', 'markings', 'money', 'icy', 'desk', 'flock', 'pair', 'geese', 'natural', 'bowling', 'alley', 'musicians', 'ship', 'tulips', 'oklahoma', 'compete', 'how', 'followed', 'doberman', 'eight', 'so', 'silly', 'lead', 'chalk', 'new', 'lips', 'sleeved', 'post', 'stuck', 'attempt', 'beneath', 'sets', 'figure', 'fabric', 'foliage', 'narrow', 'fishes', 'bends', 'brunette', 'lifts', 'lands', 'teal', 'shade', 'bleachers', 'partially', 'scales', 'gallery', 'emerges', 'crawling', 'bounds', 'bounce', 'barren', 'teammate', 'headfirst', 'concert', 'photographs', 'wheels', 'mostly', 'swimsuits', 'fruit', 'worker', 'guard', 'glove', 'cheerleader', 'runners', 'camel', 'shoe', 'athlete', 'camels', 'treat', 'pillow', 'sheer', 'headed', 'drive', 'traveling', 'chew', 'van', 'plant', 'sneakers', 'hood', 'weather', 'caps', 'floral', 'males', 'daughter', 'pitch', 'racers', 'slightly', 'females', 'casting', 'monument', 'tops', 'speaks', 'touch', 'second', 'athletic', 'style', 'amidst', 'cloud', 'bathroom', 'distant', 'participate', 'pale', 'autumn', 'flipping', 'meadow', 'sniffs', 'stripes', 'grabs', 'polka', 'plaza', 'cape', 'starting', 'breaking', 'buckets', 'rear', 'robe', 'been', 'sail', 'deer', 'houses', 'officers', 'jockeys', 'tied', 'skyline', 'infant', 'chocolate', 'driveway', 'helmeted', 'relaxing', 'spins', 'advertisement', 'luggage', 'approaching', 'bikinis', 'jack', 'playpen', 'khaki', 'wakeboarding', 'stool', 'shaved', 'business', 'push', 'musical', 'instrument', 'retrieves', 'tossing', 'marked', 'bath', 'boarding', 'gentleman', 'bay', 'leafy', 'branches', 'murky', 'arena', 'jewelry', 'buried', 'electric', 'bathtub', 'festival', 'position', 'stairway', 'bush', 'human', 'crouched', 'campfire', 'candy', 'hardhat', 'pet', 'arcade', 'opponent', 'space', 'control', 'broken', 'binoculars', 'crossed', 'roof', 'masks', 'crying', 'whistle', 'sledding', 'shovel', 'speeds', 'grabbing', 'midst', 'straight', 'beagle', 'point', 'robes', 'appear', 'jumper', 'fireworks', 'stair', 'crane', 'elephant', 'tri', 'pigtails', 'meal', 'suv', 'flat', 'fountains', 'artist', 'follow', 'navy', 'intersection', 'cage', 'toddlers', 'strange', 'pacifier', 'reflection', 'uphill', 'club', 'wakeboard', 'booth', 'stops', 'lines', 'still', 'logs', 'either', 'bungee', 'tag', 'waist', 'scenic', 'kayaks', 'visible', 'diver', 'horizon', 'countryside', 'dimly', 'knees', 'link', 'dreadlocks', 'uniformed', 'tugging', 'multiple', 'clad', 'read', 'dusty', 'ponytail', 'opens', 'stretching', 'rowboat', 'photographed', 'flames', 'shoveling', 'horseback', 'digs', 'tripod', 'belly', 'numbered', 'stars', 'jockey', 'advertising', 'sparklers', 'kites', 'traditional', 'mural', 'soft', 'tv', 'pony', 'drawing', 'barn', 'pointed', 'snowmobile', 'cows', 'star', 'swimmers', 'opening', 'jogs', 'pushed', 'descending', 'growling', 'hiding', 'approaches', 'trotting', 'waterskier', 'hikes', 'checkered', 'floaties', 'museum', 'silhouetted', 'covers', 'swords', 'lane', 'far', 'tosses', 'camping', 'tub', 'excited', 'paw', 'lighting', 'fisherman', 'enclosed', 'gestures', 'attack', 'mall', 'slip', 'handlebars', 'performer', 'oriental', 'spot', 'wild', 'balance', 'costumed', 'dot', 'lounge', 'poodles', 'gliding', 'bundled', 'identical', 'cameras', 'snowcapped', 'toilet', 'individuals', 'doors', 'rollerskating', 'poster', 'dancer', 'stretches', 'cast', 'motorcyclists', 'apple', 'aerial', 'ridge', 'wig', 'sweaters', 'cards', 'firetruck', 'picks', 'office', 'hut', 'nighttime', 'feather', 'pathway', 'soaked', 'paints', 'wades', 'relaxes', 'snowboarders', 'tropical', 'items', 'summer', 'carts', 'windows', 'weeds', 'vendor', 'selling', 'underwear', 'stare', 'husky', 'barks', 'reflective', 'tight', 'power', 'skimpy', 'was', 'clapping', 'marker', 'shoots', 'laptop', 'pick', 'brother', 'handles', 'tattooed', 'hardwood', 'pen', 'goat', 'mom', 'cooking', 'babies', 'pedestrians', 'graffitied', 'fuzzy', 'rings', 'dribbling', 'parka', 'canoes', 'collars', 'chicken', 'army', 'tiny', 'wand', 'rally', 'color', 'ran', 'trainer', 'umbrellas', 'dropping', 'colourful', 'batman', 'railings', 'flute', 'crown', 'fan', 'squirted', 'burning', 'ribbons', 'sing', 'trashcan', 'member', 'helicopter', 'bee', 'dish', 'skateboarders', 'descends', 'dive', 'multicolor', 'come', 'incline', 'sunlight', 'elaborate', 'fireplace', 'sprays', 'folding', 'seaweed', 'stretch', 'sporting', 'flowery', 'stretched', 'cushion', 'sat', 'leashed', 'blocking', 'wakeboarder', 'including', 'leotard', 'headdress', 'boards', 'heavily', 'posts', 'own', 'peeks', 'leaf', 'container', 'overhead', 'parasailing', 'handle', 'facial', 'bouncy', 'limb', 'bottles', 'bread', 'halloween', 'tricycles', 'choppy', 'aqua', 'casts', 'floppy', 'works', 'tights', 'glider', 'calm', 'bounding', 'mess', 'hurdles', 'native', 'wade', 'observes', 'fellow', 'kicked', 'similar', 'snake', 'beverage', 'bearing', 'footballer', 'cheer', 'injured', 'skies', 'pitching', 'studio', 'bunny', 'carpeted', 'pan', 'drag', 'motor', 'seagulls', 'bridesmaids', 'cannon']\n"
     ]
    }
   ],
   "source": [
    "print(new_totalwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('threshold vocab.txt','w') as f:\n",
    "    f.write(str(new_totalwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can open this file as well directly and avoid the steps in the middle\n",
    "with open('threshold vocab.txt','r') as f:\n",
    "    new_totalwords= f.read()\n",
    "json_acceptable_string2 = new_totalwords.replace(\"'\",\"\\\"\")\n",
    "new_totalwords = json.loads(json_acceptable_string2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we don't have a training and testing data separately \n",
    "#instead we have a traing and testing file which contais names of all files that should be used as training or testing\n",
    "#also note that last entry is empty for both training and testing text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filedata = readTextfile(\"flickr8k/Flickr_Data/Flickr_Data/Flickr_TextData/Flickr_8k.trainImages.txt\")\n",
    "test_filedata = readTextfile(\"flickr8k/Flickr_Data/Flickr_Data/Flickr_TextData/Flickr_8k.testImages.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [row.split(\".\")[0] for row in train_filedata.split(\"\\n\")[:-1]] \n",
    "#splitting about . part because we don't want .jpg added \n",
    "#also we take all elements except last one that's why negative indexing \n",
    "test = [row.split(\".\")[0] for row in test_filedata.split(\"\\n\")[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Description for the Training Data\n",
    "# Tweak - Add <s> and <e> token to our training data\n",
    "#<s> is for start sequence and <e> is for end sequence \n",
    "#and these are necessary for the model to actually realize from where the sentence starts so as to start prediction \n",
    "#and where to end it\n",
    "\n",
    "traindescriptions = {}\n",
    "\n",
    "for imgid in train:\n",
    "    traindescriptions[imgid] = []\n",
    "    for cap in descriptions[imgid]:\n",
    "        captoappend = \"startseq \"  + cap + \" endseq\"\n",
    "        traindescriptions[imgid].append(captoappend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq child in pink dress is climbing up set of stairs in an entry way endseq',\n",
       " 'startseq girl going into wooden building endseq',\n",
       " 'startseq little girl climbing into wooden playhouse endseq',\n",
       " 'startseq little girl climbing the stairs to her playhouse endseq',\n",
       " 'startseq little girl in pink dress going into wooden cabin endseq']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindescriptions[\"1000268201_693b08cb0e\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "- Images --> Features\n",
    "- Text ---> Features\n",
    "\n",
    "## Step - 1 Image Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# we use pre trained resnet 50 model \n",
    "#notice that this has another column connected to which is there because resnet has skip connections \n",
    "#to avoid vanishing gradients\n",
    "model = ResNet50(weights=\"imagenet\",input_shape=(224,224,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the second last layer takes input of (7,7,2048) and gives us an output of (2048)\n",
    "#this happens because it takes into each 7*7 layer which contains info about a certain feature\n",
    "#and the global average pooling layer takes each of those 7*7 input and replaces them with one value w\n",
    "#whether that feature is there or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#taking the entire model except the final dense layer which flatten and gives the prediction\n",
    "# we do this using the model API\n",
    "modelnew = Model(model.input,model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to pre process the images\n",
    "def preprocess_img(img):\n",
    "    img = image.load_img(img,target_size=(224,224)) #target size is a tuple of image height and image width\n",
    "    img = image.img_to_array(img) #Converts a PIL Image instance to a Numpy array.\n",
    "    img = np.expand_dims(img,axis=0) \n",
    "    #we will feed our model the images in batches, so input dim will be 4d i.e. (batch_size,224,224,3)\n",
    "    #to do this we use the expand_dims function\n",
    "    \n",
    "    # Normalisation\n",
    "    #resnet 50 has this feature which normalizes the image \n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMG_PATH = \"flickr8k/Flickr_Data/Flickr_Data/Images/\"\n",
    "img = preprocess_img(IMG_PATH+\"1000268201_693b08cb0e.jpg\")\n",
    "plt.imshow(img[0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(img):\n",
    "    \n",
    "    #gives the preprocessed image this image is fed to the resnet model\n",
    "    img = preprocess_img(img)\n",
    "    \n",
    "    #gives the output of the global pooling layer which for a single image will be 1X2048\n",
    "    feature_vector = modelnew.predict(img)\n",
    "    \n",
    "    \n",
    "    feature_vector = feature_vector.reshape((-1,)) #reshape to form a single row\n",
    "#     print(feature_vector)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IMG_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-df0df2132d01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mencode_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMG_PATH\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"1000268201_693b08cb0e.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'IMG_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "encode_image(IMG_PATH+\"1000268201_693b08cb0e.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-8e09f05bf2f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#taking the training data and enumerating it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIMG_PATH\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mencoding_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not iterable"
     ]
    }
   ],
   "source": [
    "#to clock the time to do the job\n",
    "start = time()\n",
    "\n",
    "#a dictionary to map the encoding vector with the image \n",
    "encoding_train = {}\n",
    "#image_id -->feature_vector extracted from Resnet Image\n",
    "\n",
    "#taking the training data and enumerating it  \n",
    "for ix,img_id in enumerate(train):\n",
    "    img_path = IMG_PATH+\"/\"+img_id+\".jpg\"\n",
    "    encoding_train[img_id] = encode_image(img_path)\n",
    "    \n",
    "    # to check the progress\n",
    "    if ix%100==0:\n",
    "        print(\"Encoding in Progress Time step %d \"%ix)\n",
    "        \n",
    "end_t = time()\n",
    "print(\"Total Time Taken :\",end_t-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store everything to the disk using pickle library\n",
    "with open(\"saved/encoded_train_features.pkl\",\"wb\") as f:\n",
    "    pickle.dump(encoding_train,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding in Progress Time step 0 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-156-bd98357e629d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIMG_PATH\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mencoding_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# to check the progress\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-b6c3c3b7a08b>\u001b[0m in \u001b[0;36mencode_image\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#gives the preprocessed image this image is fed to the resnet model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#gives the output of the global pooling layer which for a single image will be 1X2048\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-2e98807e1075>\u001b[0m in \u001b[0;36mpreprocess_img\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#function to pre process the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#target size is a tuple of image height and image width\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Converts a PIL Image instance to a Numpy array.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\u001b[0m in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[0;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'grayscale'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'L'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2842\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2843\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#doing the same things with test set as well\n",
    "\n",
    "\n",
    "start = time()\n",
    "\n",
    "#a dictionary to map the encoding vector with the image \n",
    "encoding_test = {}\n",
    "#image_id -->feature_vector extracted from Resnet Image\n",
    "\n",
    "#taking the training data and enumerating it  \n",
    "for ix,img_id in enumerate(test):\n",
    "    img_path = IMG_PATH+\"/\"+img_id+\".jpg\"\n",
    "    encoding_test[img_id] = encode_image(img_path)\n",
    "    \n",
    "    # to check the progress\n",
    "    if ix%100==0:\n",
    "        print(\"Encoding in Progress Time step %d \"%ix)\n",
    "        \n",
    "end_t = time()\n",
    "print(\"Total Time Taken :\",end_t-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saved/encoded_test_features.pkl\",\"wb\") as f:\n",
    "    pickle.dump(encoding_test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"saved/encoded_train_features2.pkl\",\"wb\") as f:\n",
    "    pickle.dump(encoding_train,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saved/encoded_test_features2.pkl\",\"wb\") as f:\n",
    "    pickle.dump(encoding_test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the encoding vectors from \n",
    "with open(\"saved/encoded_train_features.pkl\",\"rb\") as t:\n",
    "    train_encode = pickle.load(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"saved/encoded_test_features.pkl\",\"rb\") as t:\n",
    "    test_encode = pickle.load(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing for captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#we are going to reserve 0th index for padded space \n",
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "\n",
    "for i,word in enumerate(new_totalwords):\n",
    "    word_to_idx[word] = i+1\n",
    "    idx_to_word[i+1] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1845\n"
     ]
    }
   ],
   "source": [
    "word_to_idx[\"dog\"]\n",
    "\n",
    "idx_to_word[1]\n",
    "print(len(idx_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size 1848\n"
     ]
    }
   ],
   "source": [
    "# Also adding startseq and endseq to the dictionaries as well\n",
    "\n",
    "idx_to_word[1846] = 'startseq'\n",
    "word_to_idx['startseq'] = 1846\n",
    "\n",
    "idx_to_word[1847] = 'endseq'\n",
    "word_to_idx['endseq'] = 1847\n",
    "\n",
    "vocab_size = len(word_to_idx) + 1\n",
    "print(\"Vocab Size\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "#finding maximum length of a caption \n",
    "max_len = 0 \n",
    "for key in traindescriptions.keys():\n",
    "    for cap in traindescriptions[key]:\n",
    "        max_len = max(max_len,len(cap.split()))\n",
    "        \n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to define our own data generators as the data generated is quite large\n",
    "#and we need to feed the model our data in batches\n",
    "#but the generator provided by keras is not good enough for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(train_descriptions,encoding_train,word_to_idx,max_len,batch_size):\n",
    "    X1,X2, y = [],[],[]\n",
    "    \n",
    "    n =0\n",
    "    while True:\n",
    "        for key,desc_list in train_descriptions.items():\n",
    "            n += 1\n",
    "            \n",
    "            photo = encoding_train[key]\n",
    "            for desc in desc_list:\n",
    "                \n",
    "                seq = [word_to_idx[word] for word in desc.split() if word in word_to_idx]\n",
    "                for i in range(1,len(seq)):\n",
    "                    xi = seq[0:i]\n",
    "                    yi = seq[i]\n",
    "                    \n",
    "                    #0 denote padding word\n",
    "                    xi = pad_sequences([xi],maxlen=max_len,value=0,padding='post')[0]\n",
    "                    yi = to_categorical([yi],num_classes=vocab_size)[0]\n",
    "                    \n",
    "                    X1.append(photo)\n",
    "                    X2.append(xi)\n",
    "                    y.append(yi)\n",
    "                    \n",
    "                if n==batch_size:\n",
    "                    yield [[np.array(X1),np.array(X2)],np.array(y)]\n",
    "                    X1,X2,y = [],[],[]\n",
    "                    n = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = open('glove.6B.50d.txt',encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dict from glove embeddings \n",
    "embedding_index = {}\n",
    "\n",
    "for line in embedding:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    word_embedding = np.array(values[1:],dtype='float')\n",
    "    embedding_index[word] = word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.26381 , -0.31832 , -1.0953  ,  1.3305  ,  0.24761 ,  0.045313,\n",
       "       -0.39509 , -0.52107 , -0.016796,  0.33175 , -0.53252 ,  0.43263 ,\n",
       "        1.2306  , -0.36963 ,  0.15989 , -0.433   , -0.29768 ,  0.768   ,\n",
       "        0.71255 , -0.85675 , -0.076953, -1.0284  ,  0.9337  ,  0.24969 ,\n",
       "       -0.13985 ,  1.0316  , -0.15809 ,  0.80512 ,  0.50535 , -0.50557 ,\n",
       "        1.1237  , -0.45083 , -0.27552 ,  1.3537  ,  0.3553  ,  0.39403 ,\n",
       "       -1.1213  ,  0.027925,  0.57582 , -0.63611 , -0.53506 , -0.080186,\n",
       "       -0.78026 , -1.1595  ,  1.0318  ,  0.94337 ,  0.026387, -0.96839 ,\n",
       "        0.54497 , -0.16479 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_index['mango'] #note that length is 50 or it is a 50 dimensional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will take all the words that are in our vocabulary and map it with the corresponding embedding vector\n",
    "#this creates a matrix of dim(len of vocab,50)\n",
    "def get_embeddingmatrix():\n",
    "    #generating a matrix \n",
    "    emb_dim = 50\n",
    "    matrix = np.zeros((vocab_size,emb_dim))\n",
    "    for word,idx in word_to_idx.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        \n",
    "        if embedding_vector is not None:\n",
    "            matrix[idx] = embedding_vector\n",
    "            \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1848, 50)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = get_embeddingmatrix()\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[1847] \n",
    "# as endseq is not there in glove embeddings, it is instead represented by a array of 50 zeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model archiitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notice that there are two separate input layers created, one for the image and one for the captions\n",
    "#they will be passed together in the input array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the input layer\n",
    "input_img_features = Input(shape=(2048,))\n",
    "\n",
    "inp_img1 = Dropout(0.3)(input_img_features) #adding dropout layer for preventing overfitting\n",
    "\n",
    "inp_img2 = Dense(256,activation='relu')(inp_img1) #this method says that input of inp_img2 will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Captions as Input\n",
    "input_captions = Input(shape=(max_len,))\n",
    "inp_cap1 = Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(input_captions) \n",
    "#this layer is added before lstm layer\n",
    "inp_cap2 = Dropout(0.3)(inp_cap1)\n",
    "inp_cap3 = LSTM(256)(inp_cap2) #lstm layer with 256 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder1 = add([inp_img2,inp_cap3])\n",
    "decoder2 = Dense(256,activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size,activation='softmax')(decoder2)\n",
    "\n",
    "# Combined Model\n",
    "model = Model(inputs=[input_img_features,input_captions],outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 35)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 35, 50)       92400       input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 2048)         0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 35, 50)       0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          524544      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 256)          314368      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 256)          0           dense_7[0][0]                    \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 256)          65792       add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1848)         474936      dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,472,040\n",
      "Trainable params: 1,472,040\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that the embedding layer we got, \n",
    "#we set its weights beforehand and we also set it as untrainable \n",
    "model.layers[2].set_weights([embedding_matrix])\n",
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 3\n",
    "steps = len(traindescriptions)//batch_size #they should be equal to number of \n",
    "print(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 793s 396ms/step - loss: 4.2942\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 801s 400ms/step - loss: 3.5779\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 797s 399ms/step - loss: 3.3229\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 799s 400ms/step - loss: 3.1673\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 810s 405ms/step - loss: 3.0541\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 798s 399ms/step - loss: 2.9714\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 813s 407ms/step - loss: 2.9039\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 814s 407ms/step - loss: 2.8463\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 796s 398ms/step - loss: 2.7997\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 798s 399ms/step - loss: 2.7604\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 805s 402ms/step - loss: 2.7272\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 801s 400ms/step - loss: 2.6971\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 798s 399ms/step - loss: 2.6713\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 829s 415ms/step - loss: 2.6460\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 847s 423ms/step - loss: 2.6241\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 911s 455ms/step - loss: 2.6022\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 925s 462ms/step - loss: 2.5857\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 904s 452ms/step - loss: 2.5709\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 865s 433ms/step - loss: 2.5530\n",
      "Epoch 1/1\n",
      "  49/2000 [..............................] - ETA: 14:18 - loss: 2.5070"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-045544439948>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mgenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindescriptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_encode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_to_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#keras has fit generator function which gives us\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model_weights/model_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    generator = data_generator(traindescriptions,train_encode,word_to_idx,max_len,batch_size)\n",
    "    #keras has fit generator function which gives us \n",
    "    model.fit_generator(generator,epochs=1,steps_per_epoch=steps,verbose=1)\n",
    "    model.save('./model_weights/model_'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./model_weights/model_18.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_caption(photo):\n",
    "    \n",
    "    in_text = \"startseq\" #start the sentence with startseq\n",
    "    for i in range(max_len):\n",
    "        sequence = [word_to_idx[w] for w in in_text.split() if w in word_to_idx] #\n",
    "        sequence = pad_sequences([sequence],maxlen=max_len,padding='post') \n",
    "        \n",
    "        ypred = model.predict([photo,sequence])\n",
    "        ypred = ypred.argmax() #Word with max prob always - Greedy Sampling\n",
    "        word = idx_to_word[ypred]\n",
    "        in_text += (' ' + word)\n",
    "        \n",
    "        if word == \"endseq\":\n",
    "            break\n",
    "    \n",
    "    final_caption = in_text.split()[1:-1] # removing startseq and endseq and getting each word\n",
    "    final_caption = ' '.join(final_caption)\n",
    "    return final_caption\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = \"flickr8k/Flickr_Data/Flickr_Data/Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-76-159ceebb1c08>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-76-159ceebb1c08>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    img_name = all_img_names[idx] N\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Pick Some Random Images and See Results\n",
    "plt.style.use(\"seaborn\")\n",
    "for i in range(15):\n",
    "    idx = np.random.randint(0,1000) # out of the 1000 test images we randomly select some images\n",
    "    all_img_names = list(test_encode.keys())\n",
    "    img_name = all_img_names[idx] #image names of the images we selected \n",
    "    photo_2048 = test_encode[img_name].reshape((1,2048)) #reshape the flattened array of dimension (2048,)\n",
    "    \n",
    "    i = plt.imread(IMG_PATH+img_name+\".jpg\")\n",
    "    \n",
    "    caption = predict_caption(photo_2048)\n",
    "    #print(caption)\n",
    "    \n",
    "    plt.title(caption)\n",
    "    plt.imshow(i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
